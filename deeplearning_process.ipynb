{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
      "     |████████████████████████████████| 35.0 MB 3.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /opt/bitnami/python/lib/python3.8/site-packages (from pyarrow) (1.24.1)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-11.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.evaluation import *\n",
    "# import pyspark.pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sparktorch import serialize_torch_obj, SparkTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 15:14:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/07 15:14:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Vu dep trai\").config(\"spark.executor.memory\",\"10g\").getOrCreate()\n",
    "# conf = pyspark.SparkConf().setMaster(\"spark://node-master:7077\")\\\n",
    "#         .setAppName(\"Vu dep trai\")\\\n",
    "#         .set(\"spark.executor.memory\",\"15g\")\n",
    "# # sc = SparkContext.getOrCreate(conf=conf)\n",
    "# # spark.stop()\n",
    "# sc = SparkContext(conf = conf)\n",
    "# spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores_raw = spark.read.csv(\"data/ba-walmart/stores.csv\", header=True, inferSchema=True)\n",
    "df_feature_raw = spark.read.csv(\"data/ba-walmart/features.csv\", header=True, inferSchema=True)\n",
    "df_train_raw = spark.read.csv(\"data/ba-walmart/train.csv\", header=True, inferSchema=True)\n",
    "df_test_raw = spark.read.csv(\"data/ba-walmart/test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_feature_raw.drop(\"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\")\n",
    "df = df_train_raw.join(df_feature, how=\"left\", on=[\"Store\", \"Date\", \"IsHoliday\"], ).join(df_stores_raw, how=\"left\", on=[\"Store\"])\n",
    "df_test = df_test_raw.join(df_feature, how=\"left\", on=[\"Store\", \"Date\", \"IsHoliday\"]).join(df_stores_raw, how=\"left\", on=[\"Store\"])\n",
    "df = df.withColumn(\"CPI\", df[\"CPI\"].cast(FloatType())).withColumn(\"Unemployment\", df[\"Unemployment\"].cast(FloatType()))\n",
    "df_test = df_test.withColumn(\"CPI\", df_test[\"CPI\"].cast(FloatType())).withColumn(\"Unemployment\", df_test[\"Unemployment\"].cast(FloatType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Year\", year(\"Date\")).withColumn(\"Month\", month(\"Date\")).withColumn(\"Week\", weekofyear(\"Date\"))\n",
    "df_test = df_test.withColumn(\"Year\", year(\"Date\")).withColumn(\"Month\", month(\"Date\")).withColumn(\"Week\", weekofyear(\"Date\"))\n",
    "df = df.withColumn(\"IsHoliday\", df[\"IsHoliday\"].cast(IntegerType()))\n",
    "df_test = df_test.withColumn(\"IsHoliday\", df_test[\"IsHoliday\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.filter(df[\"Weekly_Sales\"] > 0)\n",
    "df_clean = df_clean.filter(df_clean[\"Weekly_Sales\"] < 450000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = df_clean.select(\"Type\").distinct().collect()\n",
    "types.sort()\n",
    "mapping = {t.Type: str(i) for i, t in enumerate(types)}\n",
    "df_clean = df_clean.replace(mapping, subset=[\"Type\"])\n",
    "df_test = df_test.replace(mapping, subset=[\"Type\"])\n",
    "df_clean = df_clean.withColumn(\"Type\", df_clean[\"Type\"].cast(IntegerType()))\n",
    "df_test = df_test.withColumn(\"Type\", df_test[\"Type\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From EDA select important columns\n",
    "drop_col = ['Date', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Month']\n",
    "# input_col = ['Store', 'IsHoliday', 'Type', 'Size', 'Week','Dept','Year']\n",
    "onehot_col = ['Store', 'Type']\n",
    "target = 'Weekly_Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_scale = df_clean.agg({\"Weekly_Sales\": \"mean\"}).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Size</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Store_1</th>\n",
       "      <th>Store_2</th>\n",
       "      <th>Store_3</th>\n",
       "      <th>Store_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Store_39</th>\n",
       "      <th>Store_40</th>\n",
       "      <th>Store_41</th>\n",
       "      <th>Store_42</th>\n",
       "      <th>Store_43</th>\n",
       "      <th>Store_44</th>\n",
       "      <th>Store_45</th>\n",
       "      <th>Type_0</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059020</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109019</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098496</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045947</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051687</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsHoliday  Dept  Weekly_Sales      Size  Year      Week  Store_1  Store_2  \\\n",
       "0        0.0   0.0      0.059020  0.630267   0.0  0.078431      1.0      0.0   \n",
       "1        1.0   0.0      0.109019  0.630267   0.0  0.098039      1.0      0.0   \n",
       "2        0.0   0.0      0.098496  0.630267   0.0  0.117647      1.0      0.0   \n",
       "3        0.0   0.0      0.045947  0.630267   0.0  0.137255      1.0      0.0   \n",
       "4        0.0   0.0      0.051687  0.630267   0.0  0.156863      1.0      0.0   \n",
       "\n",
       "   Store_3  Store_4  ...  Store_39  Store_40  Store_41  Store_42  Store_43  \\\n",
       "0      0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2      0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3      0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4      0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   Store_44  Store_45  Type_0  Type_1  Type_2  \n",
       "0       0.0       0.0     1.0     0.0     0.0  \n",
       "1       0.0       0.0     1.0     0.0     0.0  \n",
       "2       0.0       0.0     1.0     0.0     0.0  \n",
       "3       0.0       0.0     1.0     0.0     0.0  \n",
       "4       0.0       0.0     1.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean.drop(*drop_col)\n",
    "df_clean = df_clean.na.drop()\n",
    "df_clean_pd = df_clean.toPandas()\n",
    "min_target = df_clean_pd[target].min()\n",
    "max_target = df_clean_pd[target].max()\n",
    "for oh_cols in onehot_col:\n",
    "    df_clean_pd = pd.concat([df_clean_pd, pd.get_dummies(df_clean_pd[oh_cols], prefix=oh_cols)], axis=1)\n",
    "    df_clean_pd = df_clean_pd.drop(oh_cols, axis=1)\n",
    "    \n",
    "df_clean_pd = (df_clean_pd - df_clean_pd.min()) / (df_clean_pd.max() - df_clean_pd.min())\n",
    "df_clean_pd = df_clean_pd.dropna()\n",
    "df_clean_pd = df_clean_pd.reset_index(drop=True)\n",
    "df_clean_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bitnami/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/bitnami/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "df_clean = spark.createDataFrame(df_clean_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max scaler\n",
    "all_col = df_clean.columns\n",
    "all_col.remove(target)\n",
    "mm_assembler = VectorAssembler(inputCols=all_col, outputCol=\"features\")\n",
    "mm_pipeline = pyspark.ml.Pipeline(stages=[mm_assembler]).fit(df_clean)\n",
    "df_clean = mm_pipeline.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 15:16:10 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "23/02/07 15:16:10 WARN TaskSetManager: Stage 16 contains a task of very large size (16633 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 15:16:14 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 16 (TID 24): Attempting to kill Python Worker\n",
      "+-------------------+\n",
      "|Weekly_Sales       |\n",
      "+-------------------+\n",
      "|0.05901994249481135|\n",
      "|0.10901918001495786|\n",
      "|0.0984961529339467 |\n",
      "|0.04594658606039068|\n",
      "|0.05168734897215822|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_clean[[\"Weekly_Sales\"]].show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 80% first data for training\n",
    "df_train, df_valid = df_clean.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(53, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 1)\n",
    ")\n",
    "\n",
    "torch_obj = serialize_torch_obj(\n",
    "    model=net,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.0001\n",
    ")\n",
    "\n",
    "spark_model = SparkTorch(\n",
    "    inputCol='features',\n",
    "    labelCol=target,\n",
    "    predictionCol=\"prediction\",\n",
    "    torchObj=torch_obj,\n",
    "    # miniBatch=1000,\n",
    "    iters=15,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 15:16:15 WARN TaskSetManager: Stage 17 contains a task of very large size (16633 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.004410120192915201, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.0019760557916015387, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.003026119200512767, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.004651714116334915, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.0037486867513507605, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.006622850429266691, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.003869755892083049, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.006897099781781435, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.008397001773118973, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.0035698162391781807, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.005088840611279011, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 0. Distributed Loss: None Partition Training Loss: 0.001954340608790517, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.003644778626039624, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.003930910024791956, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.005607991944998503, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.0031254333443939686, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.0030121507588773966, Partition Validation Loss: NonePartition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.0042357356287539005, Partition Validation Loss: None\n",
      "\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.0024540615268051624, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.0014978920808061957, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.005938766524195671, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.0015144123462960124, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.007272256072610617, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 1. Distributed Loss: None Partition Training Loss: 0.0029257754795253277, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.0025125208776444197, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.0012775324285030365, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.005212170071899891, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.004835933912545443, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.0034395349211990833, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.0031242191325873137, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.002529321238398552, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.002120161661878228, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.002611870178952813, Partition Validation Loss: NonePartition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.0036212794948369265, Partition Validation Loss: None\n",
      "\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.006385236978530884, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 2. Distributed Loss: None Partition Training Loss: 0.0012756912037730217, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.0020122870337218046, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.003167139831930399, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.0023204442113637924, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.0012502089375630021, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.005733123514801264, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.0012730181915685534, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.0023657726123929024, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.004715805407613516, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.004302704706788063, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.002241927431896329, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.0032386784441769123, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 3. Distributed Loss: None Partition Training Loss: 0.002837921492755413, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.0014441149542108178, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.002176192356273532, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.005305547267198563, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.0020950196776539087, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.0022258772514760494, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.0027592149563133717, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.003089793724939227, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.004432565066963434, Partition Validation Loss: NonePartition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.0014042744878679514, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.003991712350398302, Partition Validation Loss: None\n",
      "\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.0030659865587949753, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 4. Distributed Loss: None Partition Training Loss: 0.002401332836598158, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.004320718813687563, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.0028315235394984484, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.0022932731080800295, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.0017124719452112913, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.0022586972918361425, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.0038621784187853336, Partition Validation Loss: NonePartition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.0030526528134942055, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.002273449907079339, Partition Validation Loss: None\n",
      "\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.0031499797478318214, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.002568160416558385, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.0016646904405206442, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 5. Distributed Loss: None Partition Training Loss: 0.005071353167295456, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.0038428669795393944, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.0027659935876727104, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.0032595214433968067, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.004308982752263546, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.0031178209464997053, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.001922733848914504, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.0023769522085785866, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.002963457489386201, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.001967877382412553, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.002500621136277914, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.002398463897407055, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 6. Distributed Loss: None Partition Training Loss: 0.0049718404188752174, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.003181879175826907, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.0020890862215310335, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.0026307839434593916, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.0038574226200580597, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.002124103717505932, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.002508163684979081, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.0033387551084160805, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.0024575102142989635, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.004938243422657251, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.0029046402778476477, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.0030680689960718155, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 7. Distributed Loss: None Partition Training Loss: 0.00432240217924118, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.0029471316374838352, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.004318589344620705, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.002134959911927581, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.0033527191262692213, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.002655049553140998, Partition Validation Loss: NonePartition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.0021572273690253496, Partition Validation Loss: None\n",
      "\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.004924313630908728, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.0025469264946877956, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.0024801732506603003, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.0038615267258137465, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.003105700481683016, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 8. Distributed Loss: None Partition Training Loss: 0.0032034129835665226, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.0025173432659357786, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.0020778002217411995, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.004914783872663975, Partition Validation Loss: NonePartition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.0020888361614197493, Partition Validation Loss: None\n",
      "\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.004290498793125153, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.00317980139516294, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.0033066817559301853, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.0029025375843048096, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.002589805983006954, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.0030801473185420036, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.0024489047937095165, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 9. Distributed Loss: None Partition Training Loss: 0.003846172010526061, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.0049130795523524284, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.0031279409304261208, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.002385249827057123, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.003014938673004508, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.0028004373889416456, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.002442452125251293, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.0038218689151108265, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.0024692844599485397, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.0019568412099033594, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.004250033292919397, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.0019534402526915073, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 10. Distributed Loss: None Partition Training Loss: 0.003224180778488517, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.003804088570177555, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.002349092625081539, Partition Validation Loss: NonePartition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.0049280128441751, Partition Validation Loss: None\n",
      "\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.0023278268054127693, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.0017985078739002347, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.0026730489917099476, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.0030687497928738594, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.0029365725349634886, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.002312974538654089, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.003130702069029212, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.0017981365090236068, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 11. Distributed Loss: None Partition Training Loss: 0.0042132725939154625, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.002192174317315221, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.00225110468454659, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.0025468345265835524, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.0016426319489255548, Partition Validation Loss: NonePartition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.002866275841370225, Partition Validation Loss: None\n",
      "\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.001641398179344833, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.004192863591015339, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.0030189594253897667, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.0030461486894637346, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.0038048119749873877, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.002259418135508895, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 12. Distributed Loss: None Partition Training Loss: 0.004966301843523979, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.003829288063570857, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.005028919316828251, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.0024389124009758234, Partition Validation Loss: None\n",
      "Partition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.002187751466408372, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.004195050802081823, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.002079371362924576, Partition Validation Loss: None\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.0015057597775012255, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.0028170906007289886, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.0029886073898524046, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.0022106985561549664, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.0015054198447614908, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 13. Distributed Loss: None Partition Training Loss: 0.00298229418694973, Partition Validation Loss: None\n",
      "Partition: 416b4371-dcbc-4744-9b63-8ecb6501ac56. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.0023575262166559696, Partition Validation Loss: None\n",
      "Partition: cf3d473a-96a2-4e00-a1cc-b1d4c4d29a67. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.003876117989420891, Partition Validation Loss: None\n",
      "Partition: a2ee3eef-1ac9-4fa0-9672-df93ac573d92. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.0013969069113954902, Partition Validation Loss: None\n",
      "Partition: 5a3ebddf-cd0c-4b89-84d7-884dc6eee54a. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.00511106988415122, Partition Validation Loss: None\n",
      "Partition: 31a40bca-b356-433e-a4be-2f08fb66d6ec. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.004219068214297295, Partition Validation Loss: None\n",
      "Partition: 9aa678c1-8950-4f53-a794-461601bd11bf. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.0029803370125591755, Partition Validation Loss: NonePartition: 6e8d3f4c-b9fb-4376-b7f7-b01dca17ed8b. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.0021401215344667435, Partition Validation Loss: None\n",
      "\n",
      "Partition: 5aeea3dc-1389-497b-9e60-bdb84a804306. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.001400967943482101, Partition Validation Loss: None\n",
      "Partition: 66353d31-b216-44dc-97b0-d032ae5851f2. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.001997407991439104, Partition Validation Loss: None\n",
      "Partition: cca273c7-e826-4017-a8d8-91c91dcef7a9. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.002793482970446348, Partition Validation Loss: None\n",
      "Partition: f91421cc-2f72-45d4-a4e3-ffa4a3872a9c. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.0029429979622364044, Partition Validation Loss: None\n",
      "Partition: 8f948a9e-f77c-4277-bd61-abed21f10511. Iteration: 14. Distributed Loss: None Partition Training Loss: 0.0021953394170850515, Partition Validation Loss: None\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "p = pyspark.ml.Pipeline(stages=[spark_model])\n",
    "model = p.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 15:18:19 WARN TaskSetManager: Stage 18 contains a task of very large size (16633 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|        prediction|     Weekly_Sales|\n",
      "+------------------+-----------------+\n",
      "|13293.761825739146|           3552.7|\n",
      "|13322.428919199705|          3930.41|\n",
      "|13199.183386234045|          4726.45|\n",
      "|13113.186825492381|          4790.03|\n",
      "|13317.029651020765|          4799.63|\n",
      "|13340.914175931215|          4808.68|\n",
      "|13077.778512874842|          4896.15|\n",
      "|13043.775079768897|          5172.73|\n",
      "|13364.540693854093|          5625.99|\n",
      "|13566.802439976931|          5794.35|\n",
      "|13545.655306276083|          5855.34|\n",
      "|13666.100519498586|          5991.01|\n",
      "|13431.801856943368|          6041.07|\n",
      "|13578.161040283441|          6121.23|\n",
      "|12996.342697602511|          6453.58|\n",
      "|13554.603743747473|          6635.58|\n",
      "|13593.572238150835|          6755.83|\n",
      "|13782.387729866505|           6762.8|\n",
      "|  13621.0531287539|6926.879999999999|\n",
      "|13546.284591611624|          7205.82|\n",
      "+------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pred = model.transform(df_valid).select(\"prediction\", target)\n",
    "pred = pred.withColumn(\"prediction\", pred[\"prediction\"] * (max_target - min_target) + min_target)\n",
    "pred = pred.withColumn(target, pred[target] * (max_target - min_target) + min_target)\n",
    "pred[[\"prediction\", target]].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                        (0 + 0) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 15:18:35 WARN TaskSetManager: Stage 19 contains a task of very large size (16633 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14759.186176181876"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get pred target max\n",
    "pred_pd = pred.toPandas()\n",
    "pred_pd[\"diff\"] = pred_pd[\"prediction\"] - pred_pd[target]\n",
    "pred_pd[\"diff\"].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 15:46:38 WARN TaskSetManager: Stage 20 contains a task of very large size (16633 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.               (0 + 12) / 12]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/bitnami/python/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/bitnami/python/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/bitnami/python/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mwithColumn(target, pred[target] \u001b[39m*\u001b[39m (max_target \u001b[39m-\u001b[39m min_target) \u001b[39m+\u001b[39m min_target)\n\u001b[1;32m      4\u001b[0m \u001b[39m# get pred target max\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m pred_pd \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39;49mtoPandas()\n\u001b[1;32m      6\u001b[0m pred_pd[\u001b[39m\"\u001b[39m\u001b[39mdiff\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pred_pd[\u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m-\u001b[39m pred_pd[target]\n\u001b[1;32m      7\u001b[0m pred_pd[\u001b[39m\"\u001b[39m\u001b[39mdiff\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/pandas/conversion.py:205\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m pdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_records(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect(), columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m    206\u001b[0m column_counter \u001b[39m=\u001b[39m Counter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m    208\u001b[0m corrected_dtypes: List[Optional[Type]] \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema)\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/dataframe.py:817\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sc):\n\u001b[0;32m--> 817\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mcollectToPython()\n\u001b[1;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.8/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 16:39:26 ERROR Executor: Exception in task 2.0 in stage 20.0 (TID 52): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 7.0 in stage 20.0 (TID 57): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 6.0 in stage 20.0 (TID 56): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 5.0 in stage 20.0 (TID 55): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 10.0 in stage 20.0 (TID 60): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 11.0 in stage 20.0 (TID 61): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 8.0 in stage 20.0 (TID 58): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 0.0 in stage 20.0 (TID 50): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 4.0 in stage 20.0 (TID 54): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 1.0 in stage 20.0 (TID 51): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 9.0 in stage 20.0 (TID 59): Connection reset\n",
      "23/02/07 16:39:26 ERROR Executor: Exception in task 3.0 in stage 20.0 (TID 53): Connection reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 35880)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/bitnami/python/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/bitnami/python/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/bitnami/python/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/bitnami/python/lib/python3.8/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/bitnami/spark/python/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/opt/bitnami/spark/python/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/opt/bitnami/spark/python/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/opt/bitnami/spark/python/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(df_train).select(\"prediction\", target)\n",
    "pred = pred.withColumn(\"prediction\", pred[\"prediction\"] * (max_target - min_target) + min_target)\n",
    "pred = pred.withColumn(target, pred[target] * (max_target - min_target) + min_target)\n",
    "# get pred target max\n",
    "pred_pd = pred.toPandas()\n",
    "pred_pd[\"diff\"] = pred_pd[\"prediction\"] - pred_pd[target]\n",
    "pred_pd[\"diff\"].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
