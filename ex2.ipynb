{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/28 18:42:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Vu dep trai\").getOrCreate()\n",
    "\n",
    "airportsSchema = StructType() \\\n",
    "    .add(\"id\", \"integer\") \\\n",
    "    .add(\"airport_name\", \"string\") \\\n",
    "    .add(\"city\", \"string\") \\\n",
    "    .add(\"country\", \"string\") \\\n",
    "    .add(\"iata\", \"string\") \\\n",
    "    .add(\"icao\", \"string\") \\\n",
    "    .add(\"latitude\", \"float\") \\\n",
    "    .add(\"longitude\", \"float\") \\\n",
    "    .add(\"altitude\", \"integer\") \\\n",
    "    .add(\"timezone\", \"byte\") \\\n",
    "    .add(\"dst\", \"string\") \\\n",
    "    .add(\"tz_database_timezone\", \"string\") \\\n",
    "    .add(\"type\", \"string\") \\\n",
    "    .add(\"source\", \"string\")\n",
    "\n",
    "routesSchema = StructType() \\\n",
    "    .add(\"airline\", \"string\") \\\n",
    "    .add(\"airline_id\", \"integer\") \\\n",
    "    .add(\"source_airport\", \"string\") \\\n",
    "    .add(\"source_airport_id\", \"integer\") \\\n",
    "    .add(\"destination_airport\", \"string\") \\\n",
    "    .add(\"destination_airport_id\", \"integer\") \\\n",
    "    .add(\"codeshare\", \"string\") \\\n",
    "    .add(\"stops\", \"integer\") \\\n",
    "    .add(\"equipment\", \"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------+----------------+----+----+---------+----------+--------+--------+---+--------------------+-------+-----------+\n",
      "| id|        airport_name|        city|         country|iata|icao| latitude| longitude|altitude|timezone|dst|tz_database_timezone|   type|     source|\n",
      "+---+--------------------+------------+----------------+----+----+---------+----------+--------+--------+---+--------------------+-------+-----------+\n",
      "|  1|      Goroka Airport|      Goroka|Papua New Guinea| GKA|AYGA| -6.08169|   145.392|    5282|      10|  U|Pacific/Port_Moresby|airport|OurAirports|\n",
      "|  2|      Madang Airport|      Madang|Papua New Guinea| MAG|AYMD| -5.20708|   145.789|      20|      10|  U|Pacific/Port_Moresby|airport|OurAirports|\n",
      "|  3|Mount Hagen Kagam...| Mount Hagen|Papua New Guinea| HGU|AYMH| -5.82679|   144.296|    5388|      10|  U|Pacific/Port_Moresby|airport|OurAirports|\n",
      "|  4|      Nadzab Airport|      Nadzab|Papua New Guinea| LAE|AYNZ|-6.569803| 146.72598|     239|      10|  U|Pacific/Port_Moresby|airport|OurAirports|\n",
      "|  5|Port Moresby Jack...|Port Moresby|Papua New Guinea| POM|AYPY| -9.44338|    147.22|     146|      10|  U|Pacific/Port_Moresby|airport|OurAirports|\n",
      "|  6|Wewak Internation...|       Wewak|Papua New Guinea| WWK|AYWK| -3.58383|   143.669|      19|      10|  U|Pacific/Port_Moresby|airport|OurAirports|\n",
      "|  7|  Narsarsuaq Airport|Narssarssuaq|       Greenland| UAK|BGBW|  61.1605|   -45.426|     112|      -3|  E|     America/Godthab|airport|OurAirports|\n",
      "|  8|Godthaab / Nuuk A...|    Godthaab|       Greenland| GOH|BGGH|  64.1909|  -51.6781|     283|      -3|  E|     America/Godthab|airport|OurAirports|\n",
      "|  9|Kangerlussuaq Air...| Sondrestrom|       Greenland| SFJ|BGSF| 67.01222|-50.711605|     165|      -3|  E|     America/Godthab|airport|OurAirports|\n",
      "| 10|      Thule Air Base|       Thule|       Greenland| THU|BGTL|  76.5312|  -68.7032|     251|      -4|  E|       America/Thule|airport|OurAirports|\n",
      "+---+--------------------+------------+----------------+----+----+---------+----------+--------+--------+---+--------------------+-------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports = spark.read.csv(\"data/airports.dat\", schema=airportsSchema)\n",
    "airports.createOrReplaceTempView(\"airports\")\n",
    "airports.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "routes = spark.read.csv(\"data/routes.dat\", schema=routesSchema)\n",
    "routes.show(10)\n",
    "routes.createOrReplaceTempView(\"routes\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------+-----------------+-------------------+----------------------+---------+-----+---------+\n",
      "|airline|airline_id|source_airport|source_airport_id|destination_airport|destination_airport_id|codeshare|stops|equipment|\n",
      "+-------+----------+--------------+-----------------+-------------------+----------------------+---------+-----+---------+\n",
      "|     2B|       410|           AER|             2965|                KZN|                  2990|     null|    0|      CR2|\n",
      "|     2B|       410|           ASF|             2966|                KZN|                  2990|     null|    0|      CR2|\n",
      "|     2B|       410|           ASF|             2966|                MRV|                  2962|     null|    0|      CR2|\n",
      "|     2B|       410|           CEK|             2968|                KZN|                  2990|     null|    0|      CR2|\n",
      "|     2B|       410|           CEK|             2968|                OVB|                  4078|     null|    0|      CR2|\n",
      "|     2B|       410|           DME|             4029|                KZN|                  2990|     null|    0|      CR2|\n",
      "|     2B|       410|           DME|             4029|                NBC|                  6969|     null|    0|      CR2|\n",
      "|     2B|       410|           DME|             4029|                TGK|                  null|     null|    0|      CR2|\n",
      "|     2B|       410|           DME|             4029|                UUA|                  6160|     null|    0|      CR2|\n",
      "|     2B|       410|           EGO|             6156|                KGD|                  2952|     null|    0|      CR2|\n",
      "+-------+----------+--------------+-----------------+-------------------+----------------------+---------+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "routes = spark.read.csv(\"data/routes.dat\", schema=routesSchema)\n",
    "routes.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of airports: \n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: airports; line 1 pos 21;\n'Aggregate [unresolvedalias(count(1), None)]\n+- 'UnresolvedRelation [airports], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of airports: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSELECT COUNT(*) FROM airports\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~opt/bitnami/spark/python/pyspark/sql/session.py:1034\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, **kwargs)\u001B[0m\n\u001B[1;32m   1032\u001B[0m     sqlQuery \u001B[38;5;241m=\u001B[39m formatter\u001B[38;5;241m.\u001B[39mformat(sqlQuery, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1033\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1036\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~opt/bitnami/python/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~opt/bitnami/spark/python/pyspark/sql/utils.py:196\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    192\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: Table or view not found: airports; line 1 pos 21;\n'Aggregate [unresolvedalias(count(1), None)]\n+- 'UnresolvedRelation [airports], [], false\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of airports: \")\n",
    "spark.sql(\"SELECT COUNT(*) FROM airports\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of airports DISTINCT: \n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: airports; line 1 pos 41;\n'Project [unresolvedalias('COUNT(distinct 'airport_name), None)]\n+- 'UnresolvedRelation [airports], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of airports DISTINCT: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSELECT COUNT(DISTINCT airport_name) FROM airports\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~opt/bitnami/spark/python/pyspark/sql/session.py:1034\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, **kwargs)\u001B[0m\n\u001B[1;32m   1032\u001B[0m     sqlQuery \u001B[38;5;241m=\u001B[39m formatter\u001B[38;5;241m.\u001B[39mformat(sqlQuery, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1033\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1036\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~opt/bitnami/python/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~opt/bitnami/spark/python/pyspark/sql/utils.py:196\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    192\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: Table or view not found: airports; line 1 pos 41;\n'Project [unresolvedalias('COUNT(distinct 'airport_name), None)]\n+- 'UnresolvedRelation [airports], [], false\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of airports DISTINCT: \")\n",
    "spark.sql(\"SELECT COUNT(DISTINCT airport_name) FROM airports\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Filtering airports in Greenland\")\n",
    "spark.sql(\"SELECT * FROM airports WHERE country = 'Greenland'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Joining routes and airports\")\n",
    "joined_tabel = spark.sql(\"SELECT * FROM routes JOIN airports ON routes.source_airport_id = airports.id\")\n",
    "joined_tabel.createOrReplaceTempView(\"joined_tabel\")\n",
    "joined_tabel.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Joining routes and airports\")\n",
    "joined_tabel = spark.sql(\"SELECT * FROM routes JOIN airports ON routes.source_airport_id = airports.id\")\n",
    "joined_tabel.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Count the number of flights arriving in each country\")\n",
    "spark.sql(\n",
    "    \"SELECT country, COUNT(airport_name) AS airport_count \"\n",
    "    \"FROM joined_tabel \"\n",
    "    \"GROUP BY country\"\n",
    ").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}